#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•MoE MLPå±‚æ›¿æ¢åŠŸèƒ½
éªŒè¯æ¨¡å‹å‰å‘ä¼ æ’­å’Œç»´åº¦åŒ¹é…æ˜¯å¦æ­£ç¡®
"""

import torch
import torch.nn as nn
from model.build import IRRA
from model.moe_mlp import MoEMLPLayer
import argparse

def create_test_args():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„å‚æ•°é…ç½®"""
    args = argparse.Namespace()
    
    # åŸºæœ¬æ¨¡å‹å‚æ•°
    args.dataset_name = "test"
    args.pretrain_choice = "ViT-B/16"
    args.img_size = (224, 224)
    args.stride_size = 16
    args.temperature = 0.07
    args.loss_names = "id+itc"
    args.vocab_size = 49408
    args.cmt_depth = 4
    
    # MoEç›¸å…³å‚æ•°
    args.moe_num_experts = 4
    args.moe_top_k = 2
    args.moe_modal_aux_loss_weight = 0.1
    args.moe_global_aux_loss_weight = 0.1
    
    # MoE MLPå±‚æ›¿æ¢å‚æ•°
    args.global_aux_loss_weight = 1.0
    args.modal_aux_loss_weight = 1.0
    args.moe_mlp_layers = 6  # å¯ç”¨MoE MLPæ›¿æ¢
    args.moe_mlp_lr = 1e-4
    
    return args

def test_model_structure(model):
    """æµ‹è¯•æ¨¡å‹ç»“æ„æ˜¯å¦æ­£ç¡®"""
    print("\n=== æµ‹è¯•æ¨¡å‹ç»“æ„ ===")
    
    # æ£€æŸ¥vision encoderçš„å6å±‚æ˜¯å¦å·²æ›¿æ¢ä¸ºMoE MLP
    vision_encoder = model.base_model.vision_model.encoder
    total_layers = len(vision_encoder.layers)
    print(f"Vision encoderæ€»å±‚æ•°: {total_layers}")
    
    # æ£€æŸ¥å6å±‚ï¼ˆç´¢å¼•6-11ï¼‰
    replaced_layers = []
    for i in range(6, min(12, total_layers)):
        layer = vision_encoder.layers[i]
        if isinstance(layer.mlp, MoEMLPLayer):
            replaced_layers.append(i)
            print(f"ç¬¬{i}å±‚MLPå·²æ›¿æ¢ä¸ºMoE MLP")
        else:
            print(f"ç¬¬{i}å±‚MLPä»ä¸ºåŸå§‹CLIP MLP")
    
    print(f"æˆåŠŸæ›¿æ¢çš„å±‚æ•°: {len(replaced_layers)}")
    return len(replaced_layers) > 0

def test_forward_pass(model, batch_size=2):
    """æµ‹è¯•å‰å‘ä¼ æ’­"""
    print("\n=== æµ‹è¯•å‰å‘ä¼ æ’­ ===")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    device = next(model.parameters()).device
    
    # å›¾åƒæ•°æ® (batch_size, 3, 224, 224)
    images = torch.randn(batch_size, 3, 224, 224).to(device)
    
    # æ–‡æœ¬æ•°æ® (batch_size, 77) - CLIPçš„æ ‡å‡†æ–‡æœ¬é•¿åº¦
    text_tokens = torch.randint(0, 49408, (batch_size, 77)).to(device)
    
    try:
        # æµ‹è¯•å›¾åƒç¼–ç 
        print("æµ‹è¯•å›¾åƒç¼–ç ...")
        with torch.no_grad():
            image_features = model.encode_image(images)
        print(f"å›¾åƒç‰¹å¾ç»´åº¦: {image_features.shape}")
        
        # æµ‹è¯•æ–‡æœ¬ç¼–ç 
        print("æµ‹è¯•æ–‡æœ¬ç¼–ç ...")
        with torch.no_grad():
            text_features = model.encode_text(text_tokens)
        print(f"æ–‡æœ¬ç‰¹å¾ç»´åº¦: {text_features.shape}")
        
        # æ£€æŸ¥ç»´åº¦åŒ¹é…
        if image_features.shape[-1] == text_features.shape[-1]:
            print("âœ“ å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ç»´åº¦åŒ¹é…")
            return True
        else:
            print("âœ— å›¾åƒå’Œæ–‡æœ¬ç‰¹å¾ç»´åº¦ä¸åŒ¹é…")
            return False
            
    except Exception as e:
        print(f"âœ— å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        return False

def test_moe_functionality(model):
    """æµ‹è¯•MoEåŠŸèƒ½"""
    print("\n=== æµ‹è¯•MoEåŠŸèƒ½ ===")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰MoEå±‚
    vision_encoder = model.base_model.vision_model.encoder
    moe_layers = []
    
    for i, layer in enumerate(vision_encoder.layers):
        if isinstance(layer.mlp, MoEMLPLayer):
            moe_layers.append((i, layer.mlp))
    
    if not moe_layers:
        print("æœªæ‰¾åˆ°MoEå±‚")
        return False
    
    print(f"æ‰¾åˆ°{len(moe_layers)}ä¸ªMoEå±‚")
    
    # æµ‹è¯•MoEå±‚çš„é—¨æ§ä¿¡æ¯
    device = next(model.parameters()).device
    test_input = torch.randn(2, 3, 224, 224).to(device)
    
    try:
        with torch.no_grad():
            _ = model.encode_image(test_input)
        
        # æ£€æŸ¥é—¨æ§ä¿¡æ¯
        for layer_idx, moe_layer in moe_layers:
            gate_info = moe_layer.get_gate_info()
            if gate_info:
                print(f"ç¬¬{layer_idx}å±‚MoEé—¨æ§ä¿¡æ¯: {len(gate_info)}ä¸ªæ‰¹æ¬¡")
            else:
                print(f"ç¬¬{layer_idx}å±‚MoEé—¨æ§ä¿¡æ¯ä¸ºç©º")
        
        return True
        
    except Exception as e:
        print(f"âœ— MoEåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("å¼€å§‹æµ‹è¯•MoE MLPå±‚æ›¿æ¢åŠŸèƒ½...")
    
    # åˆ›å»ºæµ‹è¯•å‚æ•°
    args = create_test_args()
    
    try:
        # åˆ›å»ºæ¨¡å‹
        print("åˆ›å»ºIRRAæ¨¡å‹...")
        model = IRRA(args, num_classes=1000)
        model.eval()
        
        # å¦‚æœæœ‰GPUï¼Œç§»åŠ¨åˆ°GPU
        if torch.cuda.is_available():
            model = model.cuda()
            print("æ¨¡å‹å·²ç§»åŠ¨åˆ°GPU")
        
        # è¿è¡Œæµ‹è¯•
        structure_ok = test_model_structure(model)
        forward_ok = test_forward_pass(model)
        moe_ok = test_moe_functionality(model)
        
        # æ€»ç»“æµ‹è¯•ç»“æœ
        print("\n=== æµ‹è¯•ç»“æœæ€»ç»“ ===")
        print(f"æ¨¡å‹ç»“æ„æµ‹è¯•: {'âœ“ é€šè¿‡' if structure_ok else 'âœ— å¤±è´¥'}")
        print(f"å‰å‘ä¼ æ’­æµ‹è¯•: {'âœ“ é€šè¿‡' if forward_ok else 'âœ— å¤±è´¥'}")
        print(f"MoEåŠŸèƒ½æµ‹è¯•: {'âœ“ é€šè¿‡' if moe_ok else 'âœ— å¤±è´¥'}")
        
        if structure_ok and forward_ok and moe_ok:
            print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼MoE MLPå±‚æ›¿æ¢åŠŸèƒ½æ­£å¸¸å·¥ä½œ")
        else:
            print("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°")
            
    except Exception as e:
        print(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()